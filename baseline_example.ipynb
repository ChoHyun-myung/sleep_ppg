{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3pKOltRh9aP"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy, AUC\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1bgteqt5Yak"
      },
      "source": [
        "# feature 정규화\n",
        "def scalingdf(df):\n",
        "    raw_feat = np.array(df['Red_Signal'])\n",
        "    raw_feat = raw_feat.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler()\n",
        "    feat = scaler.fit_transform(raw_feat)\n",
        "    df['Scaled'] = feat\n",
        "    return df\n",
        "\n",
        "# label 원핫인코딩\n",
        "def oh7class(arr):\n",
        "    newlabels = []\n",
        "    for i in range(len(arr)):\n",
        "        oh = [0]*7\n",
        "        oh[arr[i]-1] = 1\n",
        "        newlabels.append(oh)\n",
        "    newarr = np.array(newlabels)\n",
        "    return newarr\n",
        "\n",
        "# window segmentation\n",
        "def segment(data, label, window_size=2500, step=2500):     # non-overlap\n",
        "    feature_list = []\n",
        "    label_list = []\n",
        "    for i in range(0, len(data) - window_size + 1, int(step)):\n",
        "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
        "        label_list.append(stats.mode(label.iloc[i:i+window_size])[0][0][0])\n",
        "    return np.array(feature_list), np.array(label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A4hLyC6h9XT"
      },
      "source": [
        "p11 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer1-ppg-2000-01-01.csv')\n",
        "p12 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer1-ppg-2000-01-02.csv')\n",
        "a1 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer1-annotations.csv')\n",
        "\n",
        "p21 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer2-ppg-2000-01-01.csv')\n",
        "p22 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer2-ppg-2000-01-02.csv')\n",
        "a2 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer2-annotations.csv')\n",
        "\n",
        "p31 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer3-ppg-2000-01-01.csv')\n",
        "p32 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer3-ppg-2000-01-02.csv')\n",
        "a3 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer3-annotations.csv')\n",
        "\n",
        "p41 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer4-ppg-2000-01-01.csv')\n",
        "p42 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer4-ppg-2000-01-02.csv')\n",
        "a4 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer4-annotations.csv')\n",
        "\n",
        "p51 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer5-ppg-2000-01-01.csv')\n",
        "p52 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer5-ppg-2000-01-02.csv')\n",
        "a5 = pd.read_csv('/content/drive/Shareddrives/With j131g/PPG/Data/gamer5-annotations.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiNP-Pfsh9K_"
      },
      "source": [
        "# 합치기\n",
        "\n",
        "p1 = pd.concat([p11, p12], ignore_index=True)\n",
        "p2 = pd.concat([p21, p22], ignore_index=True)\n",
        "p3 = pd.concat([p31, p32], ignore_index=True)\n",
        "p4 = pd.concat([p41, p42], ignore_index=True)\n",
        "p5 = pd.concat([p51, p52], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ra-1blMh9Il",
        "outputId": "ef3a24dd-b85f-408d-83dd-daf20279c6c4"
      },
      "source": [
        "# 데이터와 레이블 매칭\n",
        "\n",
        "dfs = [p1, p2, p3, p4, p5]\n",
        "adfs = [a1, a2, a3, a4, a5]\n",
        "\n",
        "for i in range(5):\n",
        "    dfs[i]['Label'] = 0\n",
        "    for k in range(len(dfs[i])):\n",
        "        hr = dfs[i]['Time'][k][0:2]\n",
        "        if hr == '12':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][1]\n",
        "        elif hr == '13':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][2]\n",
        "        elif hr == '14':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][3]\n",
        "        elif hr == '15':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][4]\n",
        "        elif hr == '16':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][5]\n",
        "        elif hr == '17':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][6]\n",
        "        elif hr == '18':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][7]\n",
        "        elif hr == '19':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][8]\n",
        "        elif hr == '20':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][9]\n",
        "        elif hr == '21':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][10]\n",
        "        elif hr == '22':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][11]\n",
        "        elif hr == '23':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][12]\n",
        "        elif hr == '00':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][13]\n",
        "        elif hr == '01':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][14]\n",
        "        elif hr == '02':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][15]\n",
        "        elif hr == '03':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][16]\n",
        "        elif hr == '04':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][17]\n",
        "        elif hr == '05':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][18]\n",
        "        elif hr == '06':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][19]\n",
        "        elif hr == '07':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][20]\n",
        "        elif hr == '08':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][21]\n",
        "        elif hr == '09':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][22]\n",
        "        elif hr == '10':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][23]\n",
        "        elif hr == '11':\n",
        "            dfs[i]['Label'][k] = adfs[i]['Value'][24]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0uCBbXqAtux"
      },
      "source": [
        "# feature 정규화 & label 원핫인코딩\n",
        "\n",
        "dfs = [p1, p2, p3, p4, p5]\n",
        "ndfs = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = scalingdf(dfs[i])\n",
        "    df = oh7class(dfs[i])\n",
        "    ndfs.append(df)\n",
        "\n",
        "s1 = ndfs[0].copy()\n",
        "s2 = ndfs[1].copy()\n",
        "s3 = ndfs[2].copy()\n",
        "s4 = ndfs[3].copy()\n",
        "s5 = ndfs[4].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6iwk7u2J8rg"
      },
      "source": [
        "# Segment\n",
        "\n",
        "feature1, label1 = segment(pd.DataFrame(s1['Scaled']), pd.DataFrame(s1['Label']), window_size=500, step=2500)\n",
        "feature2, label2 = segment(pd.DataFrame(s2['Scaled']), pd.DataFrame(s2['Label']), window_size=500, step=2500)\n",
        "feature3, label3 = segment(pd.DataFrame(s3['Scaled']), pd.DataFrame(s3['Label']), window_size=500, step=2500)\n",
        "feature4, label4 = segment(pd.DataFrame(s4['Scaled']), pd.DataFrame(s4['Label']), window_size=500, step=2500)\n",
        "feature5, label5 = segment(pd.DataFrame(s5['Scaled']), pd.DataFrame(s5['Label']), window_size=500, step=2500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3_OhUPbKnIP"
      },
      "source": [
        "label1 = oh7class(label1)\n",
        "label2 = oh7class(label2)\n",
        "label3 = oh7class(label3)\n",
        "label4 = oh7class(label4)\n",
        "label5 = oh7class(label5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97e8FHmbVVkv"
      },
      "source": [
        "# 5. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvcxPaE8SvMD"
      },
      "source": [
        "# Metrics\n",
        "cat_acc = CategoricalAccuracy(name=\"categorical_accuracy\")\n",
        "metrics = [\n",
        "    cat_acc\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtF-708-TVdo"
      },
      "source": [
        "# Callbacks\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    patience=5, \n",
        "    verbose=1\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', \n",
        "    factor=0.1, \n",
        "    min_lr=1e-4, \n",
        "    patience=0, \n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "             early_stop,\n",
        "             reduce_lr\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNXfEH-nQoxJ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(7))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZqJ8uo_Qo3Y"
      },
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    feature1,\n",
        "    label1,\n",
        "    test_size = 0.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3m5ezTqQo0Y",
        "outputId": "f4214b23-36eb-4efa-e51c-c431ac81d00e"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1976, 500, 1)\n",
            "(1976, 7)\n",
            "(494, 500, 1)\n",
            "(494, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thlxyC2uQovM",
        "outputId": "bdbe2e47-0616-405e-e274-5adb34c8e035"
      },
      "source": [
        "history = model.fit(\n",
        "    x = x_train,\n",
        "    y = y_train,\n",
        "    batch_size = 5,\n",
        "    epochs = 20,\n",
        "    validation_data = (x_valid, y_valid),\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "396/396 [==============================] - 66s 162ms/step - loss: 0.1042 - categorical_accuracy: 0.4479 - auc: 0.7882 - val_loss: 0.1018 - val_categorical_accuracy: 0.4595 - val_auc: 0.8100\n",
            "Epoch 2/20\n",
            "396/396 [==============================] - 64s 161ms/step - loss: 0.1022 - categorical_accuracy: 0.4489 - auc: 0.8069 - val_loss: 0.1010 - val_categorical_accuracy: 0.4595 - val_auc: 0.8127\n",
            "Epoch 3/20\n",
            "396/396 [==============================] - 65s 163ms/step - loss: 0.1023 - categorical_accuracy: 0.4489 - auc: 0.8035 - val_loss: 0.1011 - val_categorical_accuracy: 0.4595 - val_auc: 0.8082\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 4/20\n",
            "396/396 [==============================] - 64s 162ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8073 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8135\n",
            "Epoch 5/20\n",
            "396/396 [==============================] - 64s 163ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8067 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8137\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 6/20\n",
            "396/396 [==============================] - 65s 163ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8070 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8122\n",
            "Epoch 7/20\n",
            "396/396 [==============================] - 65s 164ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8067 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8131\n",
            "Epoch 8/20\n",
            "396/396 [==============================] - 65s 164ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8070 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8112\n",
            "Epoch 9/20\n",
            "396/396 [==============================] - 65s 164ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8069 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8137\n",
            "Epoch 10/20\n",
            "396/396 [==============================] - 64s 162ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8068 - val_loss: 0.1009 - val_categorical_accuracy: 0.4595 - val_auc: 0.8125\n",
            "Epoch 11/20\n",
            "396/396 [==============================] - 64s 162ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8064 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8134\n",
            "Epoch 12/20\n",
            "396/396 [==============================] - 74s 187ms/step - loss: 0.1018 - categorical_accuracy: 0.4489 - auc: 0.8062 - val_loss: 0.1008 - val_categorical_accuracy: 0.4595 - val_auc: 0.8115\n",
            "Epoch 00012: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_68XV4OQose"
      },
      "source": [
        "p1_hist = pd.DataFrame(history.history)\n",
        "p1_hist_summary = pd.DataFrame(p1_hist.describe())\n",
        "p1_hist.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p1_hist.csv')\n",
        "p1_hist_summary.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p1_hist_summary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9WZSSu5Qono",
        "outputId": "93322306-d4cd-4ef2-9006-275c8e6bf3f5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(7))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    feature2,\n",
        "    label2,\n",
        "    test_size = 0.2\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x = x_train,\n",
        "    y = y_train,\n",
        "    batch_size = 5,\n",
        "    epochs = 20,\n",
        "    validation_data = (x_valid, y_valid),\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "388/388 [==============================] - 66s 168ms/step - loss: nan - categorical_accuracy: 0.1942 - val_loss: nan - val_categorical_accuracy: 0.1632\n",
            "\n",
            "Epoch 00001: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 2/20\n",
            "388/388 [==============================] - 65s 168ms/step - loss: nan - categorical_accuracy: 0.1643 - val_loss: nan - val_categorical_accuracy: 0.1632\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 3/20\n",
            "388/388 [==============================] - 65s 168ms/step - loss: nan - categorical_accuracy: 0.1643 - val_loss: nan - val_categorical_accuracy: 0.1632\n",
            "Epoch 4/20\n",
            "388/388 [==============================] - 65s 167ms/step - loss: nan - categorical_accuracy: 0.1643 - val_loss: nan - val_categorical_accuracy: 0.1632\n",
            "Epoch 5/20\n",
            "388/388 [==============================] - 65s 167ms/step - loss: nan - categorical_accuracy: 0.1643 - val_loss: nan - val_categorical_accuracy: 0.1632\n",
            "Epoch 00005: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9xRHHVfQolE"
      },
      "source": [
        "p2_hist = pd.DataFrame(history.history)\n",
        "p2_hist_summary = pd.DataFrame(p2_hist.describe())\n",
        "p2_hist.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p2_hist.csv')\n",
        "p2_hist_summary.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p2_hist_summary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUyX2wbFQoga",
        "outputId": "9d4e20f1-9aa3-4895-b26f-4d4c7e926f78"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(7))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    feature3,\n",
        "    label3,\n",
        "    test_size = 0.2\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x = x_train,\n",
        "    y = y_train,\n",
        "    batch_size = 5,\n",
        "    epochs = 20,\n",
        "    validation_data = (x_valid, y_valid),\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "386/386 [==============================] - 67s 171ms/step - loss: 0.1178 - categorical_accuracy: 0.2289 - val_loss: 0.1162 - val_categorical_accuracy: 0.2510\n",
            "Epoch 2/20\n",
            "386/386 [==============================] - 65s 169ms/step - loss: 0.1158 - categorical_accuracy: 0.2547 - val_loss: 0.1160 - val_categorical_accuracy: 0.2510\n",
            "Epoch 3/20\n",
            "386/386 [==============================] - 65s 170ms/step - loss: 0.1156 - categorical_accuracy: 0.2583 - val_loss: 0.1163 - val_categorical_accuracy: 0.2510\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 4/20\n",
            "386/386 [==============================] - 66s 170ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1160 - val_categorical_accuracy: 0.2510\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 5/20\n",
            "386/386 [==============================] - 66s 171ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 6/20\n",
            "386/386 [==============================] - 66s 171ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1160 - val_categorical_accuracy: 0.2510\n",
            "Epoch 7/20\n",
            "386/386 [==============================] - 65s 169ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 8/20\n",
            "386/386 [==============================] - 65s 168ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 9/20\n",
            "386/386 [==============================] - 65s 168ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 10/20\n",
            "386/386 [==============================] - 65s 167ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 11/20\n",
            "386/386 [==============================] - 65s 168ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 12/20\n",
            "386/386 [==============================] - 64s 167ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 13/20\n",
            "386/386 [==============================] - 64s 166ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 14/20\n",
            "386/386 [==============================] - 64s 166ms/step - loss: 0.1154 - categorical_accuracy: 0.2661 - val_loss: 0.1159 - val_categorical_accuracy: 0.2510\n",
            "Epoch 00014: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojOpQ5JnQods"
      },
      "source": [
        "p3_hist = pd.DataFrame(history.history)\n",
        "p3_hist_summary = pd.DataFrame(p3_hist.describe())\n",
        "p3_hist.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p3_hist.csv')\n",
        "p3_hist_summary.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p3_hist_summary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e0Szm0CQoa9",
        "outputId": "c9fc4bb3-ae58-41c8-8ad3-bff1ba7eab9a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(7))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    feature4,\n",
        "    label4,\n",
        "    test_size = 0.2\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x = x_train,\n",
        "    y = y_train,\n",
        "    batch_size = 5,\n",
        "    epochs = 20,\n",
        "    validation_data = (x_valid, y_valid),\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "430/430 [==============================] - 74s 168ms/step - loss: 0.0994 - categorical_accuracy: 0.4351 - val_loss: 0.0962 - val_categorical_accuracy: 0.4972\n",
            "Epoch 2/20\n",
            "430/430 [==============================] - 72s 168ms/step - loss: 0.0966 - categorical_accuracy: 0.4881 - val_loss: 0.0967 - val_categorical_accuracy: 0.4972\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 3/20\n",
            "430/430 [==============================] - 72s 168ms/step - loss: 0.0963 - categorical_accuracy: 0.4881 - val_loss: 0.0956 - val_categorical_accuracy: 0.4972\n",
            "Epoch 4/20\n",
            "430/430 [==============================] - 72s 167ms/step - loss: 0.0961 - categorical_accuracy: 0.4881 - val_loss: 0.0955 - val_categorical_accuracy: 0.4972\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 5/20\n",
            "430/430 [==============================] - 72s 167ms/step - loss: 0.0961 - categorical_accuracy: 0.4881 - val_loss: 0.0956 - val_categorical_accuracy: 0.4972\n",
            "Epoch 6/20\n",
            "430/430 [==============================] - 72s 168ms/step - loss: 0.0960 - categorical_accuracy: 0.4881 - val_loss: 0.0955 - val_categorical_accuracy: 0.4972\n",
            "Epoch 7/20\n",
            "430/430 [==============================] - 72s 168ms/step - loss: 0.0960 - categorical_accuracy: 0.4881 - val_loss: 0.0955 - val_categorical_accuracy: 0.4972\n",
            "Epoch 8/20\n",
            "430/430 [==============================] - 72s 168ms/step - loss: 0.0960 - categorical_accuracy: 0.4881 - val_loss: 0.0955 - val_categorical_accuracy: 0.4972\n",
            "Epoch 9/20\n",
            "430/430 [==============================] - 73s 169ms/step - loss: 0.0959 - categorical_accuracy: 0.4881 - val_loss: 0.0954 - val_categorical_accuracy: 0.4972\n",
            "Epoch 10/20\n",
            "430/430 [==============================] - 73s 169ms/step - loss: 0.0959 - categorical_accuracy: 0.4881 - val_loss: 0.0953 - val_categorical_accuracy: 0.4972\n",
            "Epoch 11/20\n",
            "430/430 [==============================] - 73s 170ms/step - loss: 0.0959 - categorical_accuracy: 0.4881 - val_loss: 0.0954 - val_categorical_accuracy: 0.4972\n",
            "Epoch 12/20\n",
            "430/430 [==============================] - 73s 170ms/step - loss: 0.0959 - categorical_accuracy: 0.4881 - val_loss: 0.0954 - val_categorical_accuracy: 0.4972\n",
            "Epoch 13/20\n",
            "430/430 [==============================] - 73s 169ms/step - loss: 0.0959 - categorical_accuracy: 0.4881 - val_loss: 0.0954 - val_categorical_accuracy: 0.4972\n",
            "Epoch 14/20\n",
            "430/430 [==============================] - 73s 170ms/step - loss: 0.0958 - categorical_accuracy: 0.4881 - val_loss: 0.0954 - val_categorical_accuracy: 0.4972\n",
            "Epoch 15/20\n",
            "430/430 [==============================] - 74s 171ms/step - loss: 0.0958 - categorical_accuracy: 0.4881 - val_loss: 0.0954 - val_categorical_accuracy: 0.4972\n",
            "Epoch 00015: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TzoeEhPQoYo"
      },
      "source": [
        "p4_hist = pd.DataFrame(history.history)\n",
        "p4_hist_summary = pd.DataFrame(p4_hist.describe())\n",
        "p4_hist.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p4_hist.csv')\n",
        "p4_hist_summary.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p4_hist_summary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXIveDWrQoVm",
        "outputId": "59ba9c03-3f08-48d5-f3cd-03f790625c23"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(7))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=metrics)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    feature5,\n",
        "    label5,\n",
        "    test_size = 0.2\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x = x_train,\n",
        "    y = y_train,\n",
        "    batch_size = 5,\n",
        "    epochs = 20,\n",
        "    validation_data = (x_valid, y_valid),\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "451/451 [==============================] - 79s 173ms/step - loss: 0.1205 - categorical_accuracy: 0.4959 - val_loss: 0.0920 - val_categorical_accuracy: 0.5390\n",
            "Epoch 2/20\n",
            "451/451 [==============================] - 77s 172ms/step - loss: nan - categorical_accuracy: 0.4960 - val_loss: nan - val_categorical_accuracy: 0.5390\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 3/20\n",
            "451/451 [==============================] - 78s 172ms/step - loss: nan - categorical_accuracy: 0.4960 - val_loss: nan - val_categorical_accuracy: 0.5390\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 4/20\n",
            "451/451 [==============================] - 77s 171ms/step - loss: nan - categorical_accuracy: 0.4960 - val_loss: nan - val_categorical_accuracy: 0.5390\n",
            "Epoch 5/20\n",
            "451/451 [==============================] - 76s 168ms/step - loss: nan - categorical_accuracy: 0.4960 - val_loss: nan - val_categorical_accuracy: 0.5390\n",
            "Epoch 6/20\n",
            "451/451 [==============================] - 76s 169ms/step - loss: nan - categorical_accuracy: 0.4960 - val_loss: nan - val_categorical_accuracy: 0.5390\n",
            "Epoch 00006: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P7At49NQoTB"
      },
      "source": [
        "p5_hist = pd.DataFrame(history.history)\n",
        "p5_hist_summary = pd.DataFrame(p5_hist.describe())\n",
        "p5_hist.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p5_hist.csv')\n",
        "p5_hist_summary.to_csv('/content/drive/Shareddrives/With j131g/PPG/Preprocessed_tmp2/p5_hist_summary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}